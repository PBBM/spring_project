<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>How Red Hat ported OpenJDK to 64-bit Arm: A community history</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lrhdBnHEIQ0/" /><category term="Java" /><category term="Linux" /><category term="Mac" /><category term="Open source" /><category term="Windows" /><category term="64-bit ARM" /><category term="AArch64" /><category term="OpenJDK" /><category term="RHEL" /><category term="x86" /><author><name>Andrew Haley</name></author><id>https://developers.redhat.com/blog/?p=827387</id><updated>2021-02-01T08:00:42Z</updated><published>2021-02-01T08:00:42Z</published><content type="html">&lt;p&gt;It has been quite a year for Arm Ltd., the firm that designs reduced instruction set computing (RISC) architectures for computer processors. The news that Arm-based computers will be important for the foreseeable future has even reached the &lt;a target="_blank" rel="nofollow" href="https://www.nytimes.com/2020/12/01/technology/amazon-apple-chips-intel-arm.html"&gt;mainstream media&lt;/a&gt;. At the end of 2019, Amazon Web Services announced Arm-based Graviton2 servers. In June 2020, Apple announced its plans to move Macintosh computers over to Apple silicon—which means Arm.&lt;/p&gt; &lt;p&gt;For those of us who have worked for years on Arm servers, this shift has been a long time coming.&lt;/p&gt; &lt;h2&gt;In the beginning&lt;/h2&gt; &lt;p&gt;Wind back to a day in 2011. I was having lunch at The Wrestlers (the Cambridge U.K. tech community&amp;#8217;s favorite Thai eatery) with Jon Masters, Red Hat&amp;#8217;s lead Arm architect. He had exciting news to share: Arm would produce a 64-bit architecture, and Red Hat was going to port &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) to it. We&amp;#8217;d need to solve quite a few problems to get this done, but one was particularly difficult. The software then available for the new 64-bit architecture did not include &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt;. Java is a key component of much enterprise software, so this news was a pretty big deal.&lt;/p&gt; &lt;p&gt;Someone would have to write a port. I had heard that two experts could write a bare-bones port of &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;OpenJDK&lt;/a&gt; in about a year, but that was all I knew. If my team were going to do it, we&amp;#8217;d have to learn on the job.&lt;/p&gt; &lt;p&gt;I was thrilled at the prospect of getting my teeth into such a substantial piece of work, but how could Red Hat justify starting this big project with no guarantee of success? I argued that unless we did it, we&amp;#8217;d have to pay someone. That would cost lots, so why not save money by doing it ourselves? It would be good publicity, and we&amp;#8217;d be able to build alliances. But there was another, deeper reason to keep it in-house. We&amp;#8217;d been building up a support team for OpenJDK. By writing an entire port, we&amp;#8217;d gain experience that we could not get any other way. Red Hat&amp;#8217;s management agreed (and has consistently supported the project ever since), so we were good to go.&lt;/p&gt; &lt;p&gt;I was determined to be one of the engineers on this project, but I couldn&amp;#8217;t do it alone. Fortunately, Andrew Dinn was about to join our Java team. He&amp;#8217;d worked on Java for a long time and had experience writing compilers for Lisp machines and logic languages. He&amp;#8217;d be a good fit.&lt;/p&gt; &lt;p&gt;One thing worried me: What if someone else did a port first? Then the whole effort might be wasted, along with any hope of glory. The only way to prevent that disaster was to gain first-mover advantage and do the work in public. Get it done fast, do it well, and make it free. Build it, and they will come.&lt;/p&gt; &lt;h2&gt;Starting the project&lt;/h2&gt; &lt;p&gt;We did have one problem—or rather, two. First, there was no AArch64 processor in existence. Also, persuading Arm Ltd. to give us the detailed information we needed was not easy. Persistence and help from Arm&amp;#8217;s Philippe Robin solved the documentation problem, but the lack of hardware was more difficult. It is possible to run all of OpenJDK under simulation, but the simulators at the time were painfully slow. What&amp;#8217;s worse, OpenJDK has to call out to the operating system. We would need to bootstrap all of &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; on the simulator before we could fire up Java.&lt;/p&gt; &lt;p&gt;Andrew Dinn remembers us being at breakfast at a conference when I excitedly told him that, while in the shower that morning, I&amp;#8217;d figured out what to do. We&amp;#8217;d use a simple, functional instruction set simulator, but just for the AArch64 code that we generated ourselves. The rest of the OpenJDK JVM is C++. We could run that natively at full speed on an Intel x86-based PC. Every call from C++ to Java would enter the simulator, and every call from Java back to C++ would leave the simulator and return to x86 code. But where would we get an AArch64 simulator library? &amp;#8220;We&amp;#8217;ll write one,&amp;#8221; I said. &amp;#8220;It&amp;#8217;s a RISC. How hard can it be?&amp;#8221;&lt;/p&gt; &lt;p&gt;We started in June of 2012. It took Andrew Dinn a little while to write the simulator, while I got on with writing the assembler and initial startup code. After a couple of months, we were executing Java bytecodes. The idea of writing our own simulator had been inspired. We could create complex breakpoint conditions and even record instruction traces so that we could see the instruction history when the JVM crashed. As a result, the initial porting went quickly. Looking back at the logs, I see an entry of &amp;#8220;Enough for Hello, World!&amp;#8221; on Oct 4, 2012. This was an important day: To get as far as outputting &amp;#8220;Hello, World!&amp;#8221; to the console, Java has to execute about three-quarters of a million bytecodes without crashing, and exercise much of the virtual machine.&lt;/p&gt; &lt;h2&gt;And then there were three&lt;/h2&gt; &lt;p&gt;By the summer of 2013, three of us were working on the project. Edward Nevill, a Java expert formerly of Arm Ltd., joined the project from Linaro. He was the first to get actual hardware. I was so comfortable with our little AArch64 simulator that I was very happy for someone else to debug our work on the real machine. I expected it to be a painful process. But, apart from a small problem with flushing the instruction cache and an issue with floating-point flags, it all worked! I was astonished. We&amp;#8217;d written our own simulator, compiler, and assembler from Arm&amp;#8217;s documentation. We&amp;#8217;d had no independent verification, but we&amp;#8217;d got it right.&lt;/p&gt; &lt;p&gt;Edward was a tremendous help, and by the start of 2014, we had a working port. Red Hat began shipping early releases to our partners, we and others carried on fixing bugs and improving performance, and on March 2, 2015, the AArch64 port was part of the main OpenJDK project. Oracle was great and helped and encouraged us through the tricky integration process.&lt;/p&gt; &lt;h2&gt;Consolidation and the (very) long tail&lt;/h2&gt; &lt;p&gt;There&amp;#8217;s a considerable difference between a working JVM and one that&amp;#8217;s really good. I don&amp;#8217;t know how much time has been spent on Intel/x86 OpenJDK, but it must be dozens of engineer years. It was a real challenge for us to make the AArch64 port competitive, but we had help. People from the AArch64 silicon producers and other companies joined us, and now people from all around the world are working on the port.&lt;/p&gt; &lt;p&gt;This is where Red Hat&amp;#8217;s open and collaborative approach really pays off. By forming partnerships with others, we gain a big multiplier over purely in-house software development.&lt;/p&gt; &lt;p&gt;But that&amp;#8217;s not the whole story. We&amp;#8217;d heard that Oracle was running Java on 64-bit Arm, and I wondered if it was our port. As it turned out, the port was proprietary, based on the (32-bit) Arm port Oracle already had. I was worried that Java&amp;#8217;s originator would get much better performance than we had. Eventually, someone who had used Oracle&amp;#8217;s port kindly assured me that I had nothing to worry about. I found it strange that Oracle wrote a port of its own, however. The company had permission from the beginning to use all of our code. Why write it again?&lt;/p&gt; &lt;p&gt;Eventually, Oracle freed both of its Arm 32- and 64-bit ports. That left us with two AArch64 ports in OpenJDK. Then, on November 12, 2020, Oracle &lt;a target="_blank" rel="nofollow" href="https://blogs.oracle.com/java-platform-group/update-on-64-bit-arm-support-for-oracle-openjdk-and-oracle-jdk"&gt;announced&lt;/a&gt; that it had decided to focus its resources going forward on a single 64-bit Arm port: The AArch64 port we&amp;#8217;d started at Red Hat. The 64-bit Arm support in Oracle&amp;#8217;s maintenance release of JDK 8 is now based on our port, as well.&lt;/p&gt; &lt;p&gt;Recently, with much fuss, Apple announced the Apple M1 chip, an implementation of AArch64. OpenJDK was ready for that processor and had been for five years. However, there is a layer of OpenJDK that&amp;#8217;s specific to each OS-CPU combination. Somebody had to do that work, and we soon had two volunteers: Microsoft and Azul, who worked on it together. Microsoft also ported the OS-CPU layer to Windows/AArch64.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;So, why did all this happen? The OpenJDK developer community made the decision. I believe that&amp;#8217;s because our little team stepped up with a working port early, got it into the OpenJDK mainline, and welcomed everyone who wanted to participate. We kept as many discussions as possible open. People volunteered, and we became a community. We achieved far more with this community than we ever could have hoped to do on our own. But none of it would have happened if we had not released that working port back at the start of 2014.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#38;linkname=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F02%2F01%2Fhow-red-hat-ported-openjdk-to-64-bit-arm-a-community-history%2F&amp;#038;title=How%20Red%20Hat%20ported%20OpenJDK%20to%2064-bit%20Arm%3A%20A%20community%20history" data-a2a-url="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/" data-a2a-title="How Red Hat ported OpenJDK to 64-bit Arm: A community history"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/"&gt;How Red Hat ported OpenJDK to 64-bit Arm: A community history&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lrhdBnHEIQ0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;It has been quite a year for Arm Ltd., the firm that designs reduced instruction set computing (RISC) architectures for computer processors. The news that Arm-based computers will be important for the foreseeable future has even reached the mainstream media. At the end of 2019, Amazon Web Services announced Arm-based Graviton2 servers. In June 2020, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/"&gt;How Red Hat ported OpenJDK to 64-bit Arm: A community history&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">827387</post-id><dc:creator>Andrew Haley</dc:creator><dc:date>2021-02-01T08:00:42Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/02/01/how-red-hat-ported-openjdk-to-64-bit-arm-a-community-history/</feedburner:origLink></entry><entry><title>Write a Quarkus function in two steps on Red Hat OpenShift Serverless</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gxUrQoW2pXk/" /><category term="Java" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Serverless" /><category term="Knative" /><category term="openshift" /><category term="Quarkus functions" /><category term="serverless functions" /><author><name>Daniel Oh</name></author><id>https://developers.redhat.com/blog/?p=853867</id><updated>2021-01-29T08:00:57Z</updated><published>2021-01-29T08:00:57Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions/"&gt;Serverless functions&lt;/a&gt; are driving the fast adoption of DevApps development and deployment practices today. To successfully adopt serverless functions, developers must understand how serverless capabilities are specified using a combination of cloud computing, data infrastructure, and function-oriented programming. We also need to consider resource optimization (memory and CPU) and high-performance boot and first-response times in both development and production environments. What if we didn&amp;#8217;t have to worry about all of that?&lt;/p&gt; &lt;p&gt;In this article, I&amp;#8217;ll walk you through two steps to write a serverless function with superfast boot and response times and built-in resource optimization. First, we&amp;#8217;ll use a pre-defined &lt;a href="https://developers.redhat.com/products/quarkus/getting-startedhttps://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; function project template to write a serverless function. Then, we&amp;#8217;ll deploy the function as a native executable using &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Red Hat OpenShift Serverless&lt;/a&gt;. With these two steps, we can avoid the extra work of developing a function from scratch, optimizing the application, and deploying it as a &lt;a href="https://developers.redhat.com/topics/serverless-architecture#assembly-field-sections-38375"&gt;Knative&lt;/a&gt; service in &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Step 1: Create a Quarkus function project&lt;/h2&gt; &lt;p&gt;The Knative command-line interface (&lt;code&gt;kn&lt;/code&gt;) supports simple interactions with Knative components on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift Container Platform&lt;/a&gt;. In this step, we&amp;#8217;ll use &lt;code&gt;kn&lt;/code&gt; to create a new function project based on the Quarkus runtime. See the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/serverless/installing_serverless/installing-kn.html"&gt;OpenShift Serverless documentation&lt;/a&gt; for instructions to install &lt;code&gt;kn&lt;/code&gt; for your operating system.&lt;/p&gt; &lt;p&gt;Assuming you have &lt;code&gt;kn&lt;/code&gt; installed, move to a preferred directory in your local development environment. Then, execute the following command in your terminal:&lt;/p&gt; &lt;pre&gt;$ kn func create quarkus-func -l quarkus &lt;/pre&gt; &lt;p&gt;The command generates a &lt;code&gt;quarkus-func&lt;/code&gt; directory that includes a new Quarkus project. Here&amp;#8217;s the output for our example:&lt;/p&gt; &lt;pre&gt;Project path: /Users/danieloh/Downloads/func-demo/quarkus-func Function name: quarkus-func Runtime: quarkus Trigger: http &lt;/pre&gt; &lt;p&gt;Next, use a text editor or your favorite IDE to open a &lt;code&gt;func.yaml&lt;/code&gt; file in the &lt;code&gt;quarkus-func&lt;/code&gt; project. Update the builder’s value to &lt;em&gt;native&lt;/em&gt; for building a Quarkus native executable. The native executable allows you to get Quarkus&amp;#8217;s superfast boot and first-response times and subatomic memory footprint. You should see something like this:&lt;/p&gt; &lt;pre&gt;name: quarkus-func namespace: "" runtime: quarkus image: "" imageDigest: "" trigger: http builder: native builderMap:   default: quay.io/boson/faas-quarkus-jvm-builder  jvm: quay.io/boson/faas-quarkus-jvm-builder  native: quay.io/boson/faas-quarkus-native-builder envVars: {} &lt;/pre&gt; &lt;p&gt;That&amp;#8217;s it. We can move forward to the next step, which is also the last step.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;kn&lt;/code&gt; CLI does not include a login mechanism. To log in to your OpenShift cluster, in the next step, you will need to have the &lt;code&gt;oc&lt;/code&gt; CLI installed. Once it&amp;#8217;s installed, you can use the &lt;code&gt;oc login&lt;/code&gt; command. Installation options for &lt;code&gt;oc&lt;/code&gt; will vary depending on your operating system. For more information, see the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/cli_reference/openshift_cli/getting-started-cli.html#cli-getting-started"&gt;OpenShift CLI documentation&lt;/a&gt;. Furthermore, we’ll use OpenShift Serverless features to deploy a serverless function, so you must install the OpenShift Serverless Operator to your OpenShift cluster. See the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/serverless/installing_serverless/installing-openshift-serverless.html"&gt;OpenShift Serverless documentation&lt;/a&gt; for more about installation.&lt;/p&gt; &lt;h2&gt;Step 2: Deploy a Quarkus function to OpenShift Serverless&lt;/h2&gt; &lt;p&gt;In this step, we&amp;#8217;ll build and deploy a container image based on the Quarkus function we&amp;#8217;ve just created. To start, move your working directory to the Quarkus project. Then, run the following commands in your terminal:&lt;/p&gt; &lt;pre&gt;$ oc new-project quarkus-func $ cd quarkus-func $ kn func deploy -r registry_string -n quarkus-func -v &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Be sure to replace the above &lt;code&gt;registry_string&lt;/code&gt; (&lt;code&gt;quay.io/myuser&lt;/code&gt; or &lt;code&gt;docker.io/myuser&lt;/code&gt;) with your own registry and namespace.&lt;/p&gt; &lt;p&gt;It takes a few minutes to build a native executable and containerize the application, which we&amp;#8217;ll do using &lt;a target="_blank" rel="nofollow" href="https://github.com/boson-project/buildpacks"&gt;Boson Project Buildpacks&lt;/a&gt;. Buildpacks automate the process of converting a user&amp;#8217;s function from source code into a runnable &lt;a target="_blank" rel="nofollow" href="https://github.com/opencontainers/image-spec"&gt;OCI image&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You will see the following message once the Knative service deploys the function to your OpenShift cluster:&lt;/p&gt; &lt;pre&gt;Deploying function to the cluster Creating Knative Service: quarkus--func Waiting for Knative Service to become ready Function deployed at URL: http://quarkus--func-quarkus-func.apps.cluster-boston-c079.boston-c079.sandbox1545.opentlc.com &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The deployment URL in this output will be different for your environment.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s add a &lt;code&gt;label&lt;/code&gt; to the Quarkus pod for fun. Run the following commands:&lt;/p&gt; &lt;pre&gt;$ REV_NAME=$(oc get rev | awk '{print $1}') $ oc label rev/$REV_NAME app.openshift.io/runtime=quarkus --overwrite &lt;/pre&gt; &lt;p&gt;Next, go to the developer console in your OpenShift cluster and navigate to the Topology view, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_853887" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853887" class="wp-image-853887 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-1024x623.png" alt="A Quarkus function in the OpenShift Topology view." width="640" height="389" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-1024x623.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-300x182.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM-768x467.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.06.50-AM.png 1362w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853887" class="wp-caption-text"&gt;Figure 1: Find your Quarkus serverless function in the Topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The serverless function might be terminated because the scale-to-zero interval is 30 seconds by default. We can fire up the function by entering the following command:&lt;/p&gt; &lt;pre&gt;$ curl -v FUNC_URL  \  -H 'Content-Type:application/json' \   -d '{"message": "Quarkus Native function on OpenShift Serverless"}' &lt;/pre&gt; &lt;p&gt;You should see something like this:&lt;/p&gt; &lt;pre&gt;... * Connection #0 to host quarkus--func-quarkus-func.apps.cluster-boston-c079.boston-c079.sandbox1545.opentlc.com left intact {"message":"Quarkus Native function on OpenShift Serverless"}* Closing connection 0 &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Be sure to replace the above &lt;code&gt;FUNC_URL&lt;/code&gt; with your own URL, which should be the same as the deployment URL in the previous step. (You can also find it by entering &lt;code&gt;oc get rt&lt;/code&gt;.)&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s go back to the developer console. Sending traffic to the endpoint triggers the autoscaler to scale the function, so you&amp;#8217;ll see that the Quarkus function pod has gone up automatically, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_853897" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853897" class="wp-image-853897 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-1024x464.png" alt="The Quarkus function pod in the Topology view." width="640" height="290" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-1024x464.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-300x136.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM-768x348.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.06-AM.png 1536w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853897" class="wp-caption-text"&gt;Figure 2: The autoscaler automatically scales the Quarkus function pod.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click the &lt;b&gt;View logs&lt;/b&gt; option in Figure 3 to discover the application&amp;#8217;s amazingly fast startup time.&lt;/p&gt; &lt;div id="attachment_853907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853907" class="wp-image-853907 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-1024x552.png" alt="Check the Resources view in the logs." width="640" height="345" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-1024x552.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-300x162.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.19-AM-768x414.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853907" class="wp-caption-text"&gt;Figure 3: Click View logs in the Resources view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You should see something like the startup time shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_853917" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853917" class="wp-image-853917 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-1024x227.png" alt="The startup time is 30 milliseconds." width="640" height="142" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-1024x227.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-300x66.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.26-AM-768x170.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853917" class="wp-caption-text"&gt;Figure 4: The pod logs show a startup time of 30 milliseconds.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In my example, the application took &lt;em&gt;30 milliseconds&lt;/em&gt; to start up. The startup time might be different in your environment.&lt;/p&gt; &lt;p&gt;Finally, if you want to check the (extremely low) memory usage while the function is running, go to the &lt;strong&gt;Monitoring&lt;/strong&gt; page and check the memory usage in metrics, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_853927" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM.png"&gt;&lt;img aria-describedby="caption-attachment-853927" class="wp-image-853927 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-1024x659.png" alt="The memory usage metrics page shows that the process takes around 78MB of memory." width="640" height="412" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-1024x659.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-300x193.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/Screen-Shot-2021-01-11-at-8.07.38-AM-768x494.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853927" class="wp-caption-text"&gt;Figure 5: Memory usage while the function is running.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This shows that our process is taking around 78MB of memory footprint. That&amp;#8217;s pretty compact!&lt;/p&gt; &lt;h3&gt;Conclusion&lt;/h3&gt; &lt;p&gt;This article showed you how to use OpenShift Serverless to create a function based on the Quarkus runtime with native compilation, then deploy it to an OpenShift cluster with just &lt;em&gt;two&lt;/em&gt; &lt;code&gt;kn func&lt;/code&gt; commands. It&amp;#8217;s also possible to choose a different function runtime (such as &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; or &lt;a href="https://developers.redhat.com/blog/category/go/"&gt;Go&lt;/a&gt;) and function trigger (such as HTTP or CloudEvents) than we used for this example. For a guide to creating a front-end application with a Node.js runtime and OpenShift Serverless, see &lt;a href="https://developers.redhat.com/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions/"&gt;&lt;i&gt;Create your first serverless function with Red Hat OpenShift Serverless Functions&lt;/i&gt;&lt;/a&gt;. For more about Quarkus&amp;#8217;s serverless strategy, see &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/funqy"&gt;Quarkus Funqy&lt;/a&gt;—a portable Java API that you can use to write functions deployable to Function-as-a-Service (FaaS) environments like AWS Lambda, Azure Functions, &lt;a href="https://developers.redhat.com/coderland/serverless/serverless-knative-intro"&gt;Knative&lt;/a&gt;, and Knative Events.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#38;linkname=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F29%2Fwrite-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless%2F&amp;#038;title=Write%20a%20Quarkus%20function%20in%20two%20steps%20on%20Red%20Hat%20OpenShift%20Serverless" data-a2a-url="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/" data-a2a-title="Write a Quarkus function in two steps on Red Hat OpenShift Serverless"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/"&gt;Write a Quarkus function in two steps on Red Hat OpenShift Serverless&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gxUrQoW2pXk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Serverless functions are driving the fast adoption of DevApps development and deployment practices today. To successfully adopt serverless functions, developers must understand how serverless capabilities are specified using a combination of cloud computing, data infrastructure, and function-oriented programming. We also need to consider resource optimization (memory and CPU) and high-performance boot and first-response times in [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/"&gt;Write a Quarkus function in two steps on Red Hat OpenShift Serverless&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">853867</post-id><dc:creator>Daniel Oh</dc:creator><dc:date>2021-01-29T08:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless/</feedburner:origLink></entry><entry><title type="html">Quarkus Newsletter #9</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/tFPPPdsHf4o/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-newsletter-9/</id><updated>2021-01-29T00:00:00Z</updated><content type="html">We took a little break, but now another Newsletter round of stories found! For the news below - give it a read and if you feel something is missing or have an article coming out for future Quarkus Newsletter install the bookmarklet on your laptop and phone to easily submit...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/tFPPPdsHf4o" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-newsletter-9/</feedburner:origLink></entry><entry><title>Static analysis updates in GCC 11</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1kjII0gq9pc/" /><category term="C" /><category term="Linux" /><category term="Open source" /><category term="Security" /><category term="-fanalyzer" /><category term="Fedora" /><category term="gcc" /><category term="program state" /><category term="static analysis" /><author><name>David Malcolm</name></author><id>https://developers.redhat.com/blog/?p=842257</id><updated>2021-01-28T08:00:24Z</updated><published>2021-01-28T08:00:24Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2014/09/gnu-logo.png" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://developers.redhat.com/blog/wp-content/uploads/2014/09/gnu-logo.png" alt="The GNU logo." width="179" height="173" /&gt;&lt;/a&gt;&lt;br /&gt; I work at Red Hat on the &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/"&gt;GNU Compiler Collection&lt;/a&gt; (GCC). In GCC 10, I added the new &lt;code&gt;-fanalyzer&lt;/code&gt; option, a &lt;a href="https://developers.redhat.com/blog/2020/03/26/static-analysis-in-gcc-10/"&gt;static analysis pass&lt;/a&gt; for identifying various problems at compile-time, rather than at runtime. The initial implementation was aimed at early adopters, who found a few bugs, including a security vulnerability: &lt;a target="_blank" rel="nofollow" href="https://www.theregister.com/2020/04/23/gcc_openssl_vulnerability/"&gt;CVE-2020-1967&lt;/a&gt;. Bernd Edlinger, who discovered the issue, had to wade through many false positives accompanying the real issue. Other users also managed to get the analyzer to crash on their code.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ve been rewriting the analyzer to address these issues in the next major release, &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/gcc-11/changes.html"&gt;GCC 11&lt;/a&gt;. In this article, I describe the steps I&amp;#8217;m taking to reduce the number of false positives and make this static analysis tool more robust.&lt;/p&gt; &lt;p&gt;&lt;span id="more-842257"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Tracking program states&lt;/h2&gt; &lt;p&gt;I&amp;#8217;ve been attempting to fix bugs in &lt;code&gt;-fanalyzer&lt;/code&gt; as they are reported via GCC&amp;#8217;s Bugzilla instance. The analyzer&amp;#8217;s state-tracking component in GCC 10 had many crasher bugs. The more bugs I fixed, the more bugs turned up, with no apparent slowdown in the rate of discovery. This suggested to me that I needed to rewrite the component.&lt;/p&gt; &lt;p&gt;I made at least two big mistakes in how I tracked program states in the original &lt;code&gt;-fanalyzer&lt;/code&gt; implementation. These were in how I tracked symbolic values and regions. The GCC 10 implementation attempted to assign unique IDs to these symbolic entities and canonicalize them so that different states could be compared (equivalent entities ought to have the same ID between different states). Unfortunately, there was always one more canonicalization issue.&lt;/p&gt; &lt;p&gt;In the new implementation, I&amp;#8217;ve made these entities singletons. As a result, a unique object now represents the (symbolic) initial value of a particular parameter at a function call at the entry to the analysis. The change to singletons got rid of large amounts of fiddly canonicalization code, using simple pointers instead. The implementation is simpler, faster, and I&amp;#8217;ve been able to fix all of the crasher bugs. (I&amp;#8217;m not quite sure what benefit I saw in the original approach, but hindsight is 20/20, I guess.)&lt;/p&gt; &lt;p&gt;The second big change is in what the symbolic values and regions represent. Previously, I represented a mapping to symbolic values, where the keys were symbolic access paths of memory regions. In the new implementation, I&amp;#8217;ve represented the state as mappings of clusters of bit-offsets within memory. These are sometimes concrete (for example, at a specific bit-offset) and sometimes symbolic (such as an array offset where the index is symbolic). This approach does a much better job of handling unions, pointer aliasing, and so forth. Additionally, lots of fiddly bugs &amp;#8220;fixed themselves&amp;#8221; when I switched to the new implementation, which reassured me that I was on the right track.&lt;/p&gt; &lt;h2&gt;Memory leak detection and non-determinism&lt;/h2&gt; &lt;p&gt;I had to rewrite memory leak detection for the new implementation completely. That said, the old implementation had many false positives, whereas the new one seems much less prone to them.&lt;/p&gt; &lt;p&gt;Another issue I ran into is non-determinism, where the analyzer&amp;#8217;s exact behavior would vary from invocation to invocation. At various places, the implementation would iterate though values, and the order of iteration would depend implicitly on precise pointer values due to hashing algorithms. The pointer values can differ due to address-space layout randomization, which led to different results. I&amp;#8217;ve now fixed such logic in the code to ensure that the analyzer&amp;#8217;s behavior is repeatable from run to run.&lt;/p&gt; &lt;h2&gt;Four new warnings&lt;/h2&gt; &lt;p&gt;The GCC 10 implementation of &lt;code&gt;-fanalyzer&lt;/code&gt; added 15 warnings:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Warnings relating to memory management: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-double-free&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-use-after-free&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-free-of-non-heap&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-malloc-leak&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Warnings relating to missing error-checking or misusing NULL pointers: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-possible-null-argument&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-possible-null-dereference&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-null-argument&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-null-dereference&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Warnings relating to &lt;code&gt;stdio&lt;/code&gt; streams: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-double-fclose&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-file-leak&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Warnings relating to use-after-return from stack frames: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-stale-setjmp-buffer&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-use-of-pointer-in-stale-stack-frame&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Unsafe call warning: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-unsafe-call-within-signal-handler&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Proof-of-concept warnings: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-tainted-array-index&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-exposure-through-output-file&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For GCC 11, I&amp;#8217;ve added four new warnings:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-write-to-const&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-write-to-string-literal&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-shift-count-negative&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-shift-count-overflow&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these corresponds to a pre-existing warning implemented in the C and C++ front ends, but with a &amp;#8220;&lt;code&gt;-Wanalyzer&lt;/code&gt;&amp;#8221; prefix rather than &amp;#8220;&lt;code&gt;-W&lt;/code&gt;.&amp;#8221; As an example, &lt;code&gt;-Wanalyzer-write-to-const&lt;/code&gt; corresponds to &lt;code&gt;-Wwrite-to-const&lt;/code&gt;. It&amp;#8217;s important to note that the two implementations are slightly different: Whereas the existing warning merely walks the syntax tree of a particular expression, the analyzer variant does an interprocedural path-based analysis, looking for code paths that attempt to write to a &lt;code&gt;const&lt;/code&gt; global.&lt;/p&gt; &lt;p&gt;After discussing whether to reuse the existing command-line options for such warnings, I chose to create new options to make it explicit that the warnings are implemented differently. The &lt;code&gt;-Wanalyzer&lt;/code&gt;-prefixed warnings will find more issues, but they are much more expensive at compile-time. (Though you&amp;#8217;ve already paid that price by choosing &lt;code&gt;-fanalyzer&lt;/code&gt;.)&lt;/p&gt; &lt;h2&gt;In progress: Attributes for marking APIs&lt;/h2&gt; &lt;p&gt;GCC has long had &lt;code&gt;__attribute__((malloc))&lt;/code&gt; for marking an API entry point as being a memory allocator. In previous GCC releases, this was purely a hint to the optimizer&amp;#8217;s pointer-aliasing logic. The attribute let the optimizer &amp;#8220;know&amp;#8221; that the pointer returned from the function pointed to different memory than the other pointers being optimized. The optimizer could then eliminate reads from locations that had not been clobbered after a write through the returned pointer.&lt;/p&gt; &lt;p&gt;In GCC 11, this attribute can now take an additional parameter marking which deallocator function should be called on the result. I&amp;#8217;m working on generalizing &lt;code&gt;-fanalyzer&lt;/code&gt; to warn about mismatches, leaks, and double-frees for APIs marked with this attribute. So far, however, it&amp;#8217;s unclear if the results will be useful without many additional attributes. For example, I attempted to use the following attribute to detect a leak in a Linux driver (CVE-2019-19078):&lt;/p&gt; &lt;pre&gt; extern struct urb *usb_alloc_urb(int iso_packets, gfp_t mem_flags); extern void usb_free_urb(struct urb *urb); &lt;/pre&gt; &lt;p&gt;I added the attribute to mark the &lt;code&gt;fns&lt;/code&gt; as an allocation/deallocation pair, where there is a leak of an &lt;code&gt;urb&lt;/code&gt; on an error-handling path. Unfortunately, various other functions take &lt;code&gt;struct urb *&lt;/code&gt;, and the analyzer conservatively assumes that an &lt;code&gt;urb&lt;/code&gt; passed to them might or might not be freed. It thus stops tracking state for them and only reports the issue if I disable much of the intervening code. This feature needs additional work to be useful except in the simplest cases.&lt;/p&gt; &lt;h2&gt;In progress: HTML output&lt;/h2&gt; &lt;p&gt;The analyzer&amp;#8217;s emitted control flow paths can be very verbose, so I&amp;#8217;ve been experimenting with other forms of output. I have an implementation of HTML output, in which the path information is written out to a separate HTML file. Here are a few examples:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dmalcolm.fedorapeople.org/gcc/2020-11-05/html-examples/test.c.path-1.html"&gt;Double-free bug&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dmalcolm.fedorapeople.org/gcc/2020-11-05/html-examples/signal-1.c.path-1.html"&gt;Signal handler issue&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dmalcolm.fedorapeople.org/gcc/2020-11-05/html-examples/setjmp-7.c.path-1.html"&gt;Memory leak&lt;/a&gt; (due to &lt;code&gt;longjmp&lt;/code&gt; past a &lt;code&gt;free&lt;/code&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The HTML path output shows stack frames and runs of events, using drop-shadows to give a 3D look. The idea is to highlight the stack of frames as if it were an actual stack of overlapping cards. I also added JavaScript to use &lt;code&gt;j&lt;/code&gt; and &lt;code&gt;k&lt;/code&gt; to move forward and back through control-flow events.&lt;/p&gt; &lt;p&gt;Unfortunately, the HTML output doesn&amp;#8217;t capture the warnings themselves, just the paths. Fixing that would require deep changes to GCC&amp;#8217;s diagnostics subsystem, which I&amp;#8217;m wary of doing at this point in the development cycle. So, I&amp;#8217;m not sure I&amp;#8217;ve found the best way to enable the HTML format as an option; it seems better to capture all of the diagnostics somehow as build artifacts, rather than just the paths of those diagnostics that have paths associated with them.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s next for GCC 11 and -fanalyzer&lt;/h2&gt; &lt;p&gt;We&amp;#8217;re in the bug-fixing phase of GCC 11 development, aiming for a release in the spring of 2021. The analyzer still needs a fair bit of bug-fixing, and we&amp;#8217;re working on scaling it up. I plan to focus on that for this first part of the new year. (These problems can be related, by the way: Bugs sometimes lead to loop-handling going awry. The analyzer will then attempt to effectively &lt;em&gt;unroll a loop&lt;/em&gt;, which leads to hitting a safety limit and a slow, incomplete analysis.)&lt;/p&gt; &lt;p&gt;I am still developing &lt;code&gt;-fanalyzer&lt;/code&gt; only for C in GCC 11. I added partial support for C++&amp;#8217;s &lt;code&gt;new&lt;/code&gt; and &lt;code&gt;delete&lt;/code&gt;But there are enough missing features that it&amp;#8217;s not yet worth using on real C++ code. I plan to make the analyzer robust and scalable for C code in GCC 11 and defer C++ support to GCC 12.&lt;/p&gt; &lt;p&gt;GCC 11 will be in &lt;a target="_blank" rel="nofollow" href="https://fedoraproject.org/wiki/Changes/GNUToolchain"&gt;Fedora 34&lt;/a&gt;, which should also be out in the spring of 2021. For simple code examples, you can play around with the new GCC online at &lt;a target="_blank" rel="nofollow" href="https://godbolt.org/"&gt;godbolt.org&lt;/a&gt;. Select your GCC &amp;#8220;trunk&amp;#8221; and add &lt;code&gt;-fanalyzer&lt;/code&gt; to the compiler options. Have fun!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#038;title=Static%20analysis%20updates%20in%20GCC%2011" data-a2a-url="https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/" data-a2a-title="Static analysis updates in GCC 11"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/"&gt;Static analysis updates in GCC 11&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1kjII0gq9pc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I work at Red Hat on the GNU Compiler Collection (GCC). In GCC 10, I added the new -fanalyzer option, a static analysis pass for identifying various problems at compile-time, rather than at runtime. The initial implementation was aimed at early adopters, who found a few bugs, including a security vulnerability: CVE-2020-1967. Bernd Edlinger, who [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/"&gt;Static analysis updates in GCC 11&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">5</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">842257</post-id><dc:creator>David Malcolm</dc:creator><dc:date>2021-01-28T08:00:24Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/</feedburner:origLink></entry><entry><title type="html">This Week in JBoss - 28 January 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/2fc-IpgFfFs/weekly-2021-01-28.html" /><category term="quarkus" /><category term="infinispan" /><category term="openshift" /><category term="camel" /><category term="kafka" /><category term="wildfly" /><category term="keycloak" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2021-01-28.html</id><updated>2021-01-28T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, infinispan, openshift, camel, kafka, wildfly, keycloak"&gt; &lt;h1&gt;This Week in JBoss - 28 January 2021&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello! Welcome to another edition of the JBoss Editorial that brings you news and updates from our community.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases"&gt;Releases!!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Infinispan 12 release, codenamed &lt;code&gt;Lockdown&lt;/code&gt;, brings a ton of new features and improvements. Indexing and querying capabilities have seen a number of improvements with the help of Hibernate Search integration. ProtoStream marshalling is upgraded with a new &lt;code&gt;@ProtoAdapter&lt;/code&gt; annotation that lets you easily integrate third-party classes. It’s a pretty elegant solution to what could present itself as a real headache for developers. Speaking of marshalling improvements, Infinispan 12 also makes your life easier by automatically generating and registering &lt;code&gt;SerializationContextInitializer&lt;/code&gt; implementations to marshall user types. Also notable is the SPI for cross-site replication merge conflicts, which continues on the brilliant work that team has done to provide a solution for ensuring data integrity. There’s a lot going on in Infinispan 12 and probably too much to try and sum up here so why not head over and read all the details in the &lt;a href="https://infinispan.org/blog/2021/01/25/infinispan-12-final"&gt;Infinispan 12.0.0.Final Announcement&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Congratulations to the entire Infinispan team on all the hard work.&lt;/p&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-1-11-0-final-released/"&gt;Quarkus 1.11&lt;/a&gt; is here! This release brings you RESTEasy Reactive, which is a new JAX-RS implementation for writing RESTful services. Quarkus 1.11 also introduces the Dev UI so you can quickly visualize all your loaded extensions, access docs, and more. Of course there are other things in Quarkus 1.11 but RESTEasy Reactive and the Dev UI look to be quite promising indeed.&lt;/p&gt; &lt;p&gt;The Quarkus team keep things rolling with the release of &lt;a href="https://quarkus.io/blog/intellij-quarkus-tools-1.3.0/"&gt;Quarkus Tools for IntelliJ 1.3.0&lt;/a&gt; that adds codestarts to the Quarkus project wizard.&lt;/p&gt; &lt;p&gt;link:https://www.keycloak.org//2021/01/keycloak-1202-released.html[Keycloak 12.0.2 is now available too! Head on over to their site and check it out.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_wildfly_bootable_jars_on_openshift"&gt;WildFly Bootable JARs on OpenShift&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Emmanuel Hugonnet &lt;a href="https://www.wildfly.org//news/2021/01/24/odo-bootable-jar/"&gt;shows you how to use WildFly’s bootable JAR feature&lt;/a&gt; and the &lt;code&gt;odo&lt;/code&gt; CLI tool to easily build and deploy applications on OpenShift.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_getting_started_with_apache_kafka_in_quarkus"&gt;Getting Started with Apache Kafka in Quarkus&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Clement Escoffier details how to get you started with Apache Kafka in Quarkus applications in less than 10 steps using Reactive Messaging. Clement provides a GitHub repository with the code too so take a look at his &lt;a href="https://quarkus.io/blog/getting-started-kafka/"&gt;Getting Started with Apache Kafka&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_easing_the_keycloak_integration_tests_in_kie_server_with_testcontainers"&gt;Easing the Keycloak integration tests in Kie Server with Testcontainers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Over at the Kie blog, Gonzalo Muñoz Fernández demonstrates &lt;a href="https://blog.kie.org/2021/01/keycloak-integration-tests-in-kie-server-with-testcontainers.html"&gt;using Testcontainers to quickly and easily create integration tests with Kie Server and Keycloak&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_resteasy_wadl_module_in_wildfly"&gt;RESTEasy WADL Module in WildFly&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Wei Nan gives a straightforward example of &lt;a href="https://resteasy.github.io/2021/01/18/deploy-resteasy-wadl-to-wildfly/"&gt;deploying the RESTEasy WADL module&lt;/a&gt; into WildFly.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_insights_hibernate_search_6"&gt;Quarkus Insights: Hibernate Search 6&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Have you subscribed to the &lt;a href="https://www.youtube.com/c/Quarkusio/videos"&gt;Quarkusio YouTube&lt;/a&gt; channel yet?&lt;/p&gt; &lt;p&gt;If not, head over and take a look. There are always interesting discussions and cool speakers.&lt;/p&gt; &lt;p&gt;One recent video that I really enjoyed, and is timed well with the release of Infinispan 12, is &lt;a href="https://www.youtube.com/watch?v=hwxWx-ORVwM"&gt;Episode #32&lt;/a&gt; where Yoann Rodière joins the lads and introduces us to &lt;a href="https://hibernate.org/search/releases/6.0/#whats-new"&gt;Hibernate Search 6&lt;/a&gt;. Yoann goes through all the exciting new stuff in Hibernate Search and explains how the search API gives you accurate and flexible full-text search for applications to overcome the limitations that come from SQL queries.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_apache_camel_and_java_flight_recorder"&gt;Apache Camel and Java Flight Recorder&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Claus Ibsen’s recent &lt;a href="http://www.davsclaus.com/2021/01/apache-camel-38-and-java-flight-recorder.html"&gt;Apache Camel 3.8 and Java Flight Recorder&lt;/a&gt; post breaks down how you can capture work steps with Flight Recorder to diagnose Apache Camel and improve performance.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_red_hat_developer_highlights"&gt;Red Hat Developer Highlights&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;In another Flight Recorder post, Andrew Azores gives us a great tutorial on using &lt;a href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;JDK Flight Recorder for containers&lt;/a&gt; running on OpenShift.&lt;/p&gt; &lt;p&gt;Finally, there is a great DevNation Tech Talk by Sebastien Blanc and Edson Yanaga on &lt;a href="https://developers.redhat.com/devnation/tech-talks/kubectl-quarkus"&gt;Building kubectl plugins with Quarkus&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/2fc-IpgFfFs" height="1" width="1" alt=""/&gt;</content><dc:creator>Don Naro</dc:creator><feedburner:origLink>https://www.jboss.org/posts/weekly-2021-01-28.html</feedburner:origLink></entry><entry><title type="html">Quarkus 1.11.1.Final released - Bugfixes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_ITdvGjyNJI/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-11-1-final-released/</id><updated>2021-01-27T00:00:00Z</updated><content type="html">1.11.1.Final is a maintenance release fixing bugs and improving the documentation. Thanks to all the contributors who reported issues and provided reproducers: it allowed us to make steady progress on fixing issues. Also a big thanks to all the contributors providing pull requests, be they for the code or the...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_ITdvGjyNJI" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-11-1-final-released/</feedburner:origLink></entry><entry><title>JBoss Tools and Red Hat CodeReady Studio for Eclipse 2020-09</title><link rel="alternate" type="text/html" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OYBlMzJYgxU/12.18.0.ga.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><category term="codereadystudio" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/12.18.0.ga.html</id><updated>2021-01-26T08:23:40Z</updated><published>2021-01-26T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://tools.jboss.org/downloads/jbosstools/2020-09/4.18.0.Final.html"&gt;JBoss Tools 4.18.0&lt;/a&gt; and &lt;a href="https://tools.jboss.org/downloads/devstudio/2020-09/12.18.0.GA.html"&gt;Red Hat CodeReady Studio 12.18&lt;/a&gt; for Eclipse 2020-09 are here waiting for you. Check it out!&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/blog/images/crstudio12.png" alt="crstudio12" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="installation"&gt;&lt;a class="anchor" href="#installation"&gt;&lt;/a&gt;Installation&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Red Hat CodeReady Studio comes with everything pre-bundled in its installer. Simply download it from our &lt;a href="https://developers.redhat.com/products/codeready-studio/overview/"&gt;Red Hat CodeReady product page&lt;/a&gt; and run it like this:&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;java -jar codereadystudio-&amp;lt;installername&amp;gt;.jar&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JBoss Tools or Bring-Your-Own-Eclipse (BYOE) CodeReady Studio require a bit more:&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This release requires at least Eclipse 4.17 (2020-09) but we recommend using the latest &lt;a href="https://www.eclipse.org/downloads/packages/release/2020-09/r/eclipse-ide-enterprise-java-developers"&gt;Eclipse 4.17 2020-09 JEE Bundle&lt;/a&gt; since then you get most of the dependencies preinstalled.&lt;/p&gt; &lt;/div&gt; &lt;div class="admonitionblock warning"&gt; &lt;table&gt; &lt;tr&gt; &lt;td class="icon"&gt; &lt;i class="fa icon-warning" title="Warning"&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class="content"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Java11 is now required to run Red Hat Developer Studio or JBoss Tools (this is a requirement from Eclipse 4.17). So make sure to select a Java11 JDK in the installer. You can still work with pre-Java11 JDK/JRE and projects in the tool.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Once you have installed Eclipse, you can either find us on the Eclipse Marketplace under &amp;quot;JBoss Tools&amp;quot; or &amp;quot;Red Hat CodeReady Studio&amp;quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For JBoss Tools, you can also use our update site directly.&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;http://download.jboss.org/jbosstools/photon/stable/updates/&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is new?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Our main focus for this release was an improved tooling for the Quarkus framework, improvements for container based development and bug fixing.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="openshift"&gt;&lt;a class="anchor" href="#openshift"&gt;&lt;/a&gt;OpenShift&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="devfile-based-deployments"&gt;&lt;a class="anchor" href="#devfile-based-deployments"&gt;&lt;/a&gt;Devfile based deployments&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Application Explorer view is now based on odo 2.x, which allows deployments to be based on devfile (developer oriented manifest file). The components from the default odo registry are listed with legacy S2I components:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/openshift/images/devfile.png" alt="devfile" width="600" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;It is also now possible to bootstrap from an empty project as the components from the registry may expose starter projects (sample code that will initialize your empty project).&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/openshift/images/devfile1.png" alt="devfile1" width="600" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="quarkus"&gt;&lt;a class="anchor" href="#quarkus"&gt;&lt;/a&gt;Quarkus&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="support-for-codestarts-in-new-quarkus-project-wizard"&gt;&lt;a class="anchor" href="#support-for-codestarts-in-new-quarkus-project-wizard"&gt;&lt;/a&gt;Support for codestarts in New Quarkus project wizard&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;code.quarkus.io has added a new option codestart that allows extension that support this new feature to contribute sample code in the generated project. It is enabled by default and is accessible from the second step in the wizard:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/quarkus/images/quarkus30.png" alt="quarkus30" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="server-tools"&gt;&lt;a class="anchor" href="#server-tools"&gt;&lt;/a&gt;Server Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="wildfly-22-server-adapter"&gt;&lt;a class="anchor" href="#wildfly-22-server-adapter"&gt;&lt;/a&gt;Wildfly 22 Server Adapter&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A server adapter has been added to work with Wildfly 22.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="hibernate-runtime-provider-updates"&gt;&lt;a class="anchor" href="#hibernate-runtime-provider-updates"&gt;&lt;/a&gt;Hibernate Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A number of additions and updates have been performed on the available Hibernate runtime providers.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.4 runtime provider now incorporates Hibernate Core version 5.4.27.Final and Hibernate Tools version 5.4.27.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.3 runtime provider now incorporates Hibernate Core version 5.3.20.Final and Hibernate Tools version 5.3.20.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.17.0.Final.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-next"&gt;&lt;a class="anchor" href="#what-is-next"&gt;&lt;/a&gt;What is next?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Having JBoss Tools 4.18.0 and Red Hat CodeReady Studio 12.18 out we are already working on the next release.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OYBlMzJYgxU" height="1" width="1" alt=""/&gt;</content><summary>JBoss Tools 4.18.0 and Red Hat CodeReady Studio 12.18 for Eclipse 2020-09 are here waiting for you. Check it out! Installation Red Hat CodeReady Studio comes with everything pre-bundled in its installer. Simply download it from our Red Hat CodeReady product page and run it like this: java -jar codereadystudio-&lt;installername&gt;.jar JBoss Tools or Bring-Your-Own-Eclipse (BYOE) CodeReady Studio require a bit more: This release requires at least Eclipse 4.17 (2020-09) but we recommend using the latest Eclipse 4.17 2020-09 JEE Bundle since then you get most of the dependencies preinstalled. Java11 is now required to run Red Hat Developer Studio or JBoss Tools (this is a requirement from Eclipse 4.17). So...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2021-01-26T00:00:00Z</dc:date><feedburner:origLink>https://tools.jboss.org/blog/12.18.0.ga.html</feedburner:origLink></entry><entry><title type="html">Infinispan 12.0.0.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Q_bcDy20hd8/infinispan-12-final" /><author><name>Tristan Tarrant</name></author><id>/blog/2021/01/25/infinispan-12-final</id><updated>2021-01-25T12:00:00Z</updated><content type="html">INFINISPAN 12.0.0.FINAL Dear Infinispan community, we hope you, your families and colleagues are doing well in these trying times. We’ve been working hard over the last few months to bring you a brand-new release of Infinispan. Infinispan 12, aptly codenamed comes loaded with a number of notable features as well as the usual slew of fixes and cleanups. INDEXING AND SEARCH Our good friends over at have been working hard on delivering an awesome and have also helped us integrate it in Infinispan. This is not just an upgrade: we have taken the opportunity to evolve our indexing configuration: * Upgraded to Hibernate Search 6, that brings support for Lucene 8 indexes * Better indexing performance out of the box * New statistics API, covering indexed, non-indexed and hybrid queries * Introduced strong typed indexing configuration that replaces the string key/value properties. Head over to the much improved . CONFIGURATION We introduced a couple of improvements to the configuration API: * Runtime creation of templates: the remote APIs now allow creating configuration templates. * Configuration Fragments: when creating caches and templates via the remote APIs, you no longer need to wrap their configuration in the &lt;infinispan&gt;&lt;cache-container&gt;… &lt;/cache-container&gt;&lt;/infinispan&gt; elements, but you can simply use the cache definition directly, e.g.: &lt;distributed-cache name=”mycache”/&gt; MARSHALLING * A new @ProtoAdapter annotation has been added to ProtoStream for generating .proto files and marshallers for third party classes * SerializationContextInitializer implementations are automatically discovered and configured via Java ServiceLoader. * User types are now fully isolated from Infinispan internal context. CROSS SITE REPLICATION Our work on improving asynchronous cross-site replication continues with the following improvements: * a new SPI for merging conflicting values: if two (or more) write operations happen simultaneously in different sites, the conflict is detected and the SPI is invoked to merge the values. Merge policies determine which action will be taken in case of conflict between updates of different sites. Some predefined merge policies can be found . * Exponential back-off added for network failures: ff the network between the sites disconnects, Infinispan will retry less frequently before giving up. It helps reduce the CPU utilization. * Automatic disconnection if the cache configuration does not exist or is incorrect: if Infinispan tries to backup to a remote site and the remote site doesn’t have the cache defined, the remote site is automatically taken offline. * Internal code improvements: the code is now non-blocking to reduce the CPU usage. See for more information. SERVER BACKUP/RESTORE A backup archive, that contains container resources (caches, cache templates, counters, Protobuf schemas, server tasks) currently stored in the cache manager, can now be created. The backup archive can then be used to restore Infinispan clusters content after a restart or migration. This feature is exposed via the REST endpoint, however backups can also be created via the Infinispan CLI or with Backup/Restore CRs when using the operator. CREDENTIAL STORES To protect sensitive text strings, such as passwords, in the server configuration, you can add them to a credential keystore and reference them. You can then configure the server to decrypt passwords for establishing connections with services such as databases or LDAP directories. &lt;security&gt; &lt;credential-stores&gt; &lt;credential-store name="credentials" path="credentials.pfx"&gt; &lt;clear-text-credential clear-text="secret"/&gt; &lt;/credential-store&gt; &lt;/credential-stores&gt; &lt;/security&gt; &lt;data-sources&gt; &lt;data-source name="postgres" jndi-name="jdbc/postgres"&gt; &lt;connection-factory driver="org.postgresql.Driver" username="dbuser" url="jdbc:postgresql:database"&gt; &lt;credential-reference store="credentials" alias="dbpassword"/&gt; &lt;/connection-factory&gt; &lt;/data-source&gt; &lt;/data-sources&gt; MULTIPLE ENDPOINTS The server now allows definining multiple single-port endpoints, each one mapped to a separate socket binding and with its own security realm. This is useful if you want to expose an admin endpoint on an internal, management-only network as well as an endpoint for application uses. OPTIONAL AUTHENTICATION FOR METRICS ENDPOINT Previously, the Prometheus-compatible metrics endpoint, published at , used the same security semantics as the single port endpoint. It’s now possible to allow anonymous connections to this endpoint, to simplify integration with your Prometheus scraper. CUSTOM SERVER PATHS It’s now possible to start the server by overriding each of the paths individually. server.sh -Dinfinispan.server.config.path=... \ -Dinfinispan.server.log.path=... \ -Dinfinispan.server.data.path=... \ -Dinfinispan.server.lib.path=... Moreover, the server library path now supports multiple directories which will be scanned recursively for both JARs and bare resources such as property files. NEAR CACHES WITH BLOOM FILTER The remote client has near caches that allow for values retrieved from the remote server to be cached locally on the client. This works great for workloads that are primarily read only. However, to provide consistency we have to listen to remote modification/removal events from the server, which can make work loads with a lot of writes not scale. As such we are introducing bloom filter assisted notifications that will reduce the amount of modification/removal events received from the server and thus would increase the scalability of write heavy applications using the near cache. This needs to be enabled in addition to near caching, which can be done via the client configuration xml or programmatic classes. DISTRIBUTED TRACING You can now integrate Infinispan’s server with OpenTracing to perform distributed tracing. * Only track Hot Rod cache write requests (i.e. no counters, multimap etc.) * Select the OpenTracing implementation via the infinispan.opentracing.factory.class and infinispan.opentracing.factory.method system properties. * An OpenTracing implementation (is not included: instead it must be added to the server/lib directory (for example: the Jaeger OpenTracing implementation). CLI BENCHMARK TOOL The CLI now includes a small convenience benchmark tool which allows you to measure latency and throughput of an Infinispan server using a specific configuration. You can use this when sizing resources based on your requirements. NATIVE BUILD The CLI is available as a native build, thanks to . The binaries for Linux, Mac and Windows can be found . KUBERNETES CLI When installing the native CLI as kubectl-infinispan, the CLI gains additional functionality to control the Infinispan operator, simplifying many operations. This includes the ability to install and uninstall the operator, create and delete Infinispan clusters and obtain information about various resources. CONFIGURATION IMPROVEMENTS The CLI can persist some configuration properties which you wish to apply to all your sessions: * autoconnect-url: Specifies the URL to which the CLI automatically connects on startup. * autoexec: Specifies the path of a CLI batch file to execute on startup. * truststore: Specifies the path of a truststore to validate server certificates. * trustall: Specifies whether to trust all server certificates without supplying a trust store. CONSOLE This version includes a new version of the web console, including mainly fixes, but also the ability to finally view cache entries and their details: CLOUD EVENTS INTEGRATION The Infinispan integration is a new experimental module which converts Infinispan events to CloudEvents events and sends them to a Kafka topic in structured mode. This allows Infinispan be further used as a Knative source. There are two broad kinds of events: * Cache entry modifications: created, updated, removed, expired * Audit events: user login, access denied IMAGES * A natively compiled version of the CLI is now available as a container via the image. * The server images have also added support for configuring zero-capacity as well as allowing JGroups properties to be overridden at runtime. OPERATOR The operator continues to improve and evolve so that installing and managing Infinispan clusters on Kubernetes/OpenShift is a breeze: * Data Backup and Restore are available via CR. * Cross site improvements: * Access to remote cluster k8s API is no longer mandatory. * Manual configuration. * Namespaces can be different. * Multinamespace and global installation mode. * TLS can be disabled via CR configuration, even in environments where certificate management is built-in (e.g. OpenShift). * Support for the Quarkus native Infinispan image. * Anti-affinity configuration. DOCUMENTATION * Documentation for configuring cluster transport was overhauled in Infinispan 12. We made numerous changes, based on direct feedback from the community, to our JGroups content. We also added details on how to configure SYM_ENCRYPT and ASYM_ENCRYPT protocols, which were previously available only in the JGroups documentation set. * You can find new chapters on Configuring Cluster Transport in the Server Guide and Embedding Infinispan Guide. The details for JGroups encryption are also available in the guide for Securing Infinispan. * Off-Heap configuration has often been misunderstood and we’ve had several questions about what it actually means to store data in native memory outside the JVM heap. To address these questions, and spell out some of the benefits and potential downsides of using off-heap storage, we’ve added some conceptual information to our Configuration Guide. * Our documentation on Configuring Infinispan to Marshall Java Objects is also updated in an effort to improve clarity and be more task-oriented. * Along with all the refactoring and improvements that have been made to the Search API, we’ve made some improvements to our documentation for Querying Values in Infinispan Caches. * Lastly, we noticed that the documentation for Clustered Locks was a little out of date and potentially confusing so we spent time to rework that content to make sure it’s accurate. As always, the Infinispan team hope you find the documentation useful and complete. We’d love to hear from you and really value feedback from our community. If you think something is missing from the docs or spot a correction, please get in touch and we’ll get on it straight away. OTHER * We have decided to adopt in Infinispan, both in our code and in our documentation. For example, Infinispan’s way of configuring which classes are allowed to be marshalled/unmarshalled is now called allow list. If you find other places where we are using inappropriate terms, please don’t hesitate to contact us. * We’ve added some UI writing guidelines and Infinispan terminology to our Contributor’s Guide in an effort to create a consistent user experience. * As you may have noticed, our website has gone through some extensive redesign. * Bye bye OSGI (it even rhymes !): we’ve removed support for OSGi since it was quite a maintenance burden. RELEASE NOTES AND UPGRADING You can look at the detailed to see what has changed since CR1. If you are upgrading from a previous version of Infinispan, please checkout our . WHAT’S NEXT ? Our next release, 12.1, will be a quick one, mostly focused on polishing and small API improvemnets, before we move on to bigger things. As usual, look out for blog postings about upcoming highlights. If you’d like to contribute, just get in touch.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Q_bcDy20hd8" height="1" width="1" alt=""/&gt;</content><dc:creator>Tristan Tarrant</dc:creator><feedburner:origLink>http://tools.jboss.org/blog/2021/01/25/infinispan-12-final</feedburner:origLink></entry><entry><title>Introduction to ContainerJFR: JDK Flight Recorder for containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PPHmWvkzro8/" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Open source" /><category term="ContainerJFR" /><category term="Java flight recorder" /><category term="monitor java" /><category term="OpenJDK" /><category term="profile java" /><author><name>Andrew Azores</name></author><id>https://developers.redhat.com/blog/?p=798277</id><updated>2021-01-25T08:00:18Z</updated><published>2021-01-25T08:00:18Z</published><content type="html">&lt;p&gt;OpenJDK has long been a top pick for real-world applications and workloads, chosen for its blend of performance, compatibility, reliability, and observability. For many years, JDK Flight Recorder (JFR) and JDK Mission Control (JMC) have contributed to OpenJDK&amp;#8217;s success. Until recently, both were commercial features, however, available only for certain users and workloads.&lt;/p&gt; &lt;p&gt;In 2018, JDK Mission Control and JDK Flight Recorder were open-sourced. JDK Flight Recorder is now built into the Java Virtual Machine (JVM) for later releases of OpenJDK 8 and all versions from OpenJDK 11 onward. Open-sourcing these tools brings their power—always-on, near-zero overhead production profiling and monitoring, application-specific custom events, and unified-core JDK analytical tooling—to all JDK users. On the downside, JDK Mission Control and JDK Flight Recorder have emerged into a world rapidly moving toward containerization, which is not the paradigm that they were designed for.&lt;/p&gt; &lt;p&gt;The desktop-only JDK Mission Control application requires developers and administrators to access flight recordings on the local disk. Otherwise, one resorts to a complex and potentially insecure setup to connect directly to applications over Java Management Extensions (JMX) in the cloud. Similarly, the bare-metal-focused JDK Flight Recorder allows JVMs to dump recordings into the local filesystem, but not when the application runs inside a container. In that case, the filesystem is not easily accessible from the outside world, and it isn&amp;#8217;t possible to retrieve and analyze recordings.&lt;/p&gt; &lt;p&gt;This article introduces &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;ContainerJFR&lt;/a&gt;, a young project on the way to becoming a Red Hat product. ContainerJFR seeks to bridge the gaps between JDK Flight Recorder in the cloud and end-users at their workstations.&lt;/p&gt; &lt;h2&gt;Manual ContainerJFR installation and setup&lt;/h2&gt; &lt;p&gt;Installing ContainerJFR manually is straightforward using the available images on &lt;a target="_blank" rel="nofollow" href="https://quay.io/repository/rh-jmc-team/container-jfr"&gt;Quay.io&lt;/a&gt;. Run the following for a basic installation and product demonstration:&lt;/p&gt; &lt;pre&gt;$ podman run -it --rm -p 8181 -e CONTAINER_JFR_WEB_HOST=0.0.0.0 quay.io/rh-jmc-team/container-jfr:latest &lt;/pre&gt; &lt;p&gt;For a more full-fledged demonstration, you can clone the ContainerJFR repository and run its &lt;code&gt;smoketest.sh&lt;/code&gt;. The following sets up a few containers in a Podman pod for testing and demonstration:&lt;/p&gt; &lt;pre&gt;$ git clone &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;https://github.com/rh-jmc-team/container-jfr&lt;/a&gt; $ cd container-jfr $ sh smoketest.sh &lt;/pre&gt; &lt;p&gt;ContainerJFR&amp;#8217;s credentials, in this case, are &lt;code&gt;smoketest:smoketest&lt;/code&gt;. The other application’s credentials are &lt;code&gt;admin:adminpass123&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Deploying ContainerJFR on Red Hat OpenShift&lt;/h2&gt; &lt;p&gt;If you have access to &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; or another Kubernetes cluster, you can use the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr-operator"&gt;ContainerJFR Operator&lt;/a&gt; to deploy ContainerJFR on your cluster:&lt;/p&gt; &lt;pre&gt;$ git clone &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr-operator"&gt;https://github.com/rh-jmc-team/container-jfr-operator&lt;/a&gt; $ cd container-jfr-operator $ oc login # ensure you are logged in to your running OpenShift cluster first $ make deploy # to directly deploy the Operator in your cluster along with a ContainerJFR CR, required ServiceAccount and Role/RoleBindings, etc. $ make catalog # alternative to make deploy. This will add a custom CatalogSource to your cluster, allowing you to install the Operator from your Administrator view’s OperatorHub panel &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you don’t already have access to an OpenShift or Kubernetes cluster, try &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Figure 1 shows ContainerJFR in the OpenShift OperatorHub after we&amp;#8217;ve issued a &lt;code&gt;$ make catalog&lt;/code&gt; to add a custom catalog source.&lt;/p&gt; &lt;div id="attachment_799477" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub.png"&gt;&lt;img aria-describedby="caption-attachment-799477" class="wp-image-799477 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-1024x516.png" alt="The OpenShift OperatorHub with the ContainerJFR Operator." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-1024x516.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-768x387.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799477" class="wp-caption-text"&gt;Figure 1: ContainerJFR in the OpenShift OperatorHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 2 shows a ContainerJFR instance installed in the default namespace.&lt;/p&gt; &lt;div id="attachment_799537" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1.png"&gt;&lt;img aria-describedby="caption-attachment-799537" class="wp-image-799537 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-1024x214.png" alt="The ContainerJFR Operator has been installed." width="640" height="134" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-1024x214.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-300x63.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-768x160.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799537" class="wp-caption-text"&gt;Figure 2: ContainerJFR installed in a project namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After you&amp;#8217;ve installed ContainerJFR, create a custom resource for it, as shown in Figure 3. Choose any name you like and leave the &lt;b&gt;minimal&lt;/b&gt; setting on&lt;strong&gt; false&lt;/strong&gt; for now.&lt;/p&gt; &lt;div id="attachment_799457" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr.png"&gt;&lt;img aria-describedby="caption-attachment-799457" class="wp-image-799457 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-1024x433.png" alt="The dialog to create a ContainerJFR custom resource." width="640" height="271" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-1024x433.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-768x325.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr.png 1337w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799457" class="wp-caption-text"&gt;Figure 3: Create and configure the ContainerJFR custom resource.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After a short time, the Operator finishes deploying ContainerJFR and its services. You can use any view that shows the exposed route URLs to see the ContainerJFR web client. Figure 4 shows ContainerJFR in OpenShift&amp;#8217;s Topology view.&lt;/p&gt; &lt;div id="attachment_799437" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view.png"&gt;&lt;img aria-describedby="caption-attachment-799437" class="wp-image-799437 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-1024x517.png" alt="ContainerJFR seen from the OpenShift developer console in the Topology view." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799437" class="wp-caption-text"&gt;Figure 4: ContainerJFR in the OpenShift Topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we&amp;#8217;ll take a look at ContainerJFR&amp;#8217;s major features, and I&amp;#8217;ll show you how to configure them for your container-managed OpenJDK applications.&lt;/p&gt; &lt;h2&gt;Discovery with ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR is a containerized JVM that runs as a “sidecar” alongside your OpenJDK applications. Depending on the runtime environment, it automatically selects the best strategy for discovering your JMX-enabled applications. For applications running with &lt;code&gt;docker-compose&lt;/code&gt; or &lt;code&gt;podman-compose&lt;/code&gt;, ContainerJFR would use the &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/10/management/java-discovery-protocol.htm"&gt;Java Discovery Protocol&lt;/a&gt; (JDP). For applications running on Kubernetes or OpenShift, it would use endpoints. These are only examples of the platform implementations ContainerJFR currently provides. It is easily extensible if you need customized support for a different container platform.&lt;/p&gt; &lt;h3&gt;Java Management Extensions&lt;/h3&gt; &lt;p&gt;Ensure that your applications have JMX enabled and that the JMX port is published and reachable by ContainerJFR. In practical terms, this means passing the following JVM flags when you start the application:&lt;/p&gt; &lt;pre&gt;-Dcom.sun.management.jmxremote.port=9091 -Dcom.sun.management.jmxremote.rmi.port=9091 &lt;/pre&gt; &lt;p&gt;Then, expose the port using whatever mechanism your container platform uses. In OpenShift or Kubernetes, you would create a service for your deployment and then add an exposed port to the service. By default, ContainerJFR uses port 9091 for JMX, but you can use any port number given the port is named &lt;code&gt;jfr-jmx&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Figure 5 shows ContainerJFR with two sample applications in the OpenShift Topology view.&lt;/p&gt; &lt;div id="attachment_799547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps.png"&gt;&lt;img aria-describedby="caption-attachment-799547" class="wp-image-799547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-1024x517.png" alt="The OpenShift Topology view shows ContainerJFR and two sample applications." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799547" class="wp-caption-text"&gt;Figure 5: ContainerJFR with two sample applications.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Java Discovery Protocol&lt;/h3&gt; &lt;p&gt;If you are running with Podman or Docker, or if you are running a local JVM process directly on your host machine, you should also enable Java Discovery Protocol (JDP):&lt;/p&gt; &lt;pre&gt;-Dcom.sun.management.jmxremote.autodiscovery=true &lt;/pre&gt; &lt;h2&gt;Event templates in ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR supports JDK Flight Recorder event templates, which pre-set the event types and configuration properties to be supported. Using event templates simplifies the task of capturing meaningful data for your applications. ContainerJFR also includes a view that displays all of the event types registered with the JDK Flight Recorder framework for a target JVM. This view is useful when creating or modifying your own event templates.&lt;/p&gt; &lt;p&gt;The Event Templates view in Figure 7 displays pre-set event templates that you can download to your local machine to examine or modify. After you&amp;#8217;ve modified a template, you can upload it for reuse. You can also create recordings from templates.&lt;/p&gt; &lt;div id="attachment_799587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates.png"&gt;&lt;img aria-describedby="caption-attachment-799587" class="wp-image-799587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-1024x517.png" alt="The Event Templates view in ContainerJFR." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799587" class="wp-caption-text"&gt;Figure 7: Event templates in ContainerJFR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The Event Types view in Figure 8 displays all of the event types registered with the selected target JVM. You can use this view to search for events by category, keyword, or provider.&lt;/p&gt; &lt;div id="attachment_799567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types.png"&gt;&lt;img aria-describedby="caption-attachment-799567" class="wp-image-799567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-1024x517.png" alt="The Event Types view in ContainerJFR." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799567" class="wp-caption-text"&gt;Figure 8: Event types in ContainerJFR.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Editing templates&lt;/h3&gt; &lt;p&gt;You can use ContainerJFR to download a template from a target JVM to your local machine, then open and inspect the template XML document with your favorite text editor. You can even import and edit the template using JDK Mission Control. Figure 9 shows the dialog to download an event template.&lt;/p&gt; &lt;div id="attachment_799607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-799607" class="size-large wp-image-799607" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-1024x243.png" alt="The dialog to download an event template." width="640" height="152" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-1024x243.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-300x71.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-768x182.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download.png 1599w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-799607" class="wp-caption-text"&gt;Figure 9: Download an event template to your local disk.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Custom templates&lt;/h3&gt; &lt;p&gt;After you have created a custom template or modified an existing one, you can re-upload it to ContainerJFR, where it will be retained for future use. You will be able to apply the template whenever you create new recordings across your JVM applications.&lt;/p&gt; &lt;p&gt;You can open and edit event templates using any plaintext editor. Another option is to use JDK Mission Control&amp;#8217;s graphical template editor to import, edit, and export a template. Figure 10 shows an event template in a plaintext editor.&lt;/p&gt; &lt;div id="attachment_799617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor.png"&gt;&lt;img aria-describedby="caption-attachment-799617" class="wp-image-799617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-1024x556.png" alt="An event template in a plaintext editor." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799617" class="wp-caption-text"&gt;Figure 10: Use any editor to modify an event template in XML format.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you upload a new or modified template, ContainerJFR validates it, as shown in Figure 11.&lt;/p&gt; &lt;div id="attachment_799627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload.png"&gt;&lt;img aria-describedby="caption-attachment-799627" class="wp-image-799627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-1024x456.png" alt="An event template ready for upload." width="640" height="285" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-1024x456.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-300x133.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-768x342.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799627" class="wp-caption-text"&gt;Figure 11: Templates are validated when the server receives them.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 12 shows all of the available templates for a ContainerJFR instance.&lt;/p&gt; &lt;div id="attachment_799637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded.png"&gt;&lt;img aria-describedby="caption-attachment-799637" class="wp-image-799637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-1024x233.png" alt="A list of templates available for later use." width="640" height="146" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-1024x233.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-300x68.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-768x175.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799637" class="wp-caption-text"&gt;Figure 12: A list of templates available for later use.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;All of these features also work with JDK Flight Recorder’s Custom Events API. You can create application-specific event types while developing your application, then create a custom event template including these events, and tailor your own continuous production recordings.&lt;/p&gt; &lt;h2&gt;Recordings in ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR offers several ways to capture and preserve recordings, including custom recordings, snapshots, and archives.&lt;/p&gt; &lt;h3&gt;Custom recordings&lt;/h3&gt; &lt;p&gt;Figure 13 shows the configuration properties to be defined when you set up a new custom recording.&lt;/p&gt; &lt;div id="attachment_799647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording.png"&gt;&lt;img aria-describedby="caption-attachment-799647" class="wp-image-799647 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-1024x517.png" alt="The dialog to create a custom recording." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799647" class="wp-caption-text"&gt;Figure 13: Creating a custom recording.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;First is the name of the recording, which ContainerJFR uses to enforce uniqueness per target. You will also configure the duration before the recording is automatically stopped or if it should run continuously until it is manually stopped. You will need to configure the event specifier string or template for the events you want the recording to capture. Advanced properties include “to disk,&amp;#8221; “max size,&amp;#8221; and “max age.&amp;#8221; See the &lt;a&gt;JDK Flight Recorder documentation&lt;/a&gt; to learn more about these properties.&lt;/p&gt; &lt;h3&gt;Snapshots&lt;/h3&gt; &lt;p&gt;Figure 14 shows the dialog to create a new snapshot recording. A &lt;i&gt;snapshot&lt;/i&gt; is an overview of all of the information captured by other recordings.&lt;/p&gt; &lt;div id="attachment_799677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording.png"&gt;&lt;img aria-describedby="caption-attachment-799677" class="wp-image-799677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-1024x291.png" alt="The view to create a snapshot recording." width="640" height="182" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-1024x291.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-768x218.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799677" class="wp-caption-text"&gt;Figure 14: Create a snapshot recording with one click.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you have multiple custom recordings running in a target at once, you could use a snapshot to create a new recording file at that point in time. The snapshot contains the merged data from all of your other recordings. Snapshots can also be useful for preserving data from a single, continuous recording at a particular point in time.&lt;/p&gt; &lt;h3&gt;Data flow&lt;/h3&gt; &lt;p&gt;When you create a recording, you ask ContainerJFR to send instructions to your target JVM to start a flight recording. No data is transferred outside of your application at this point, only the name, state, and start time of your recordings, along with other basic metadata. The recording lives only in the memory of your target application, within its container.&lt;/p&gt; &lt;div id="attachment_799657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list.png"&gt;&lt;img aria-describedby="caption-attachment-799657" class="wp-image-799657 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-1024x517.png" alt="The view shows a list of recordings." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799657" class="wp-caption-text"&gt;Figure 15: ContainerJFR displays all of the recordings present in a selected target JVM.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Archives&lt;/h3&gt; &lt;p&gt;&lt;i&gt;Archiving&lt;/i&gt; streams a snapshot of a recording out of your application and into ContainerJFR. ContainerJFR immediately writes the snapshot to its local disk (or a persistent volume in OpenShift or Kubernetes) and drops it from memory. Even if your application is scaled down or otherwise goes away, you will still be able to access the recording for analysis. If you accidentally delete a &lt;code&gt;.jfr&lt;/code&gt; file, you can re-upload it from your workstation’s local disk into the archives. This also works if you remove ContainerJFR from the cluster and re-install it later.&lt;/p&gt; &lt;p&gt;The archived recording list in Figure 16 displays all of the recordings saved to ContainerJFR&amp;#8217;s persistent storage, which is common across all target JVMs.&lt;/p&gt; &lt;div id="attachment_799667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list.png"&gt;&lt;img aria-describedby="caption-attachment-799667" class="wp-image-799667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-1024x517.png" alt="The view shows a list of archived recordings." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799667" class="wp-caption-text"&gt;Figure 16: Recordings saved to ContainerJFR&amp;#8217;s persistent storage.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Automated analysis with ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR lets you run an automated analysis on your flight recordings within your cloud deployment without ever needing to transfer data to your local machine or outside of the cluster. You can use this feature to check your applications&amp;#8217; health from a hotel with a slow connection or an airport using only your phone or tablet.&lt;/p&gt; &lt;p&gt;Expanding the list of active and archived recordings in Figure 17 reveals an automated analysis generated within the cluster.&lt;/p&gt; &lt;div id="attachment_799687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report.png"&gt;&lt;img aria-describedby="caption-attachment-799687" class="wp-image-799687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-1024x517.png" alt="An automated analysis report." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799687" class="wp-caption-text"&gt;Figure 17: An automated analysis report for active and archived recordings.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you expand a recording, ContainerJFR uses its JDK Mission Control back end to generate an automated analysis report, alerting you to any apparent or probable issues with your application. You can also save reports in HTML format for future reference.&lt;/p&gt; &lt;h3&gt;Using Grafana for analysis&lt;/h3&gt; &lt;p&gt;If the automated analysis report doesn’t contain enough information for you, or if it points out a problem that you want to inspect more closely, you can send the recording to the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/jfr-datasource"&gt;jfr-datasource&lt;/a&gt; exporter within the ContainerJFR pod. From there, you can view the data using &lt;a target="_blank" rel="nofollow" href="https://grafana.com"&gt;Grafana&lt;/a&gt;. Figure 18 shows the recording list item action menu, which you can use to send a recording to the Grafana dashboard.&lt;/p&gt; &lt;div id="attachment_799697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana.png"&gt;&lt;img aria-describedby="caption-attachment-799697" class="wp-image-799697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-1024x263.png" alt="The Grafana action view." width="640" height="164" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-1024x263.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-300x77.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-768x197.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799697" class="wp-caption-text"&gt;Figure 18: Send a recording to the Grafana dashboard for further analysis.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;ContainerJFR provides a pre-configured dashboard with time-series data, but you are encouraged to create your own dashboards with the metrics that matter to you. Note, again, that none of your data leaves the cluster. The &lt;code&gt;jfr-datasource&lt;/code&gt; that provides the translation from a &lt;code&gt;.jfr&lt;/code&gt; file to Grafana metrics is hidden within the ContainerJFR pod, and the Grafana dashboard instance is secured with generated credentials (stored in an OpenShift or Kubernetes secret) before being exposed to the outside world. It is easy to retrieve those generated credentials using the following commands:&lt;/p&gt; &lt;pre&gt;$ oc get secret containerjfr-grafana-basic -o json | jq -crM .data.GF_SECURITY_ADMIN_USER | base64 -d $ oc get secret containerjfr-grafana-basic -o json | jq -crM .data.GF_SECURITY_ADMIN_PASSWORD | base64 -d &lt;/pre&gt; &lt;p&gt;Once you have the credentials, you can plug them into the Grafana dashboard&amp;#8217;s login page and start viewing your metrics, as shown in Figure 19.&lt;/p&gt; &lt;div id="attachment_799717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1.png"&gt;&lt;img aria-describedby="caption-attachment-799717" class="wp-image-799717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-1024x517.png" alt="Viewing metrics in the Grafana dashboard." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799717" class="wp-caption-text"&gt;Figure 19: The preconfigured Grafana dashboard gives more detailed insights into your application&amp;#8217;s performance (batteries included and installed).&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Using JDK Mission Control for analysis&lt;/h3&gt; &lt;p&gt;Finally, if you need even more detail, you can download a recording file from ContainerJFR to your local disk and open it with the full-featured offline JDK Mission Control desktop application. This is the only scenario where your recording actually leaves the cluster.&lt;/p&gt; &lt;div id="attachment_799727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc.png"&gt;&lt;img aria-describedby="caption-attachment-799727" class="wp-image-799727 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-1024x556.png" alt="The JDK Mission Control dashboard." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799727" class="wp-caption-text"&gt;Figure 20: Use the JDK Mission Control desktop application for a deep-dive into the data collected from your cloud applications.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The JDK Mission Control desktop application offers a wealth of features and capabilities, but I will leave that discussion for another article.&lt;/p&gt; &lt;h2&gt;Secure authentication with ContainerJFR&lt;/h2&gt; &lt;p&gt;JDK Flight Recorder captures a tremendous amount of data with no significant runtime overhead. Keeping the data secure and ensuring its integrity is vital. As shown in Figure 21, ContainerJFR does not require your application to open its JMX connections to the world—only to connections from inside your OpenShift namespace or your Docker or Podman network.&lt;/p&gt; &lt;div id="attachment_852077" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0.png"&gt;&lt;img aria-describedby="caption-attachment-852077" class="wp-image-852077 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-1024x867.png" alt="A graph illustrating ContainerJFR deployment and relations between components." width="640" height="542" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-1024x867.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-300x254.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-768x650.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0.png 1137w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-852077" class="wp-caption-text"&gt;Figure 21: Overview of a secure ContainerJFR deployment.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once ContainerJFR has received a copy of your Java Flight Recorder data—which it does only upon your instruction—that data is accessible only through secured API requests. The secured API requests support JMX authentication to connect to your application and another authentication layer to connect to ContainerJFR.&lt;/p&gt; &lt;p&gt;When running in OpenShift, all sensitive API requests require a user account token for authentication, as shown in Figure 22. Note that requests from the client to ContainerJFR over HTTP or WebSocket and requests from ContainerJFR to targets over JMX all support and enable the Secure Socket Layer or Transport Layer Security (SSL/TLS) protocol by default.&lt;/p&gt; &lt;div id="attachment_799597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login.png"&gt;&lt;img aria-describedby="caption-attachment-799597" class="wp-image-799597 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-1024x517.png" alt="The ContainerJFR login page on OpenShift." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799597" class="wp-caption-text"&gt;Figure 22: ContainerJFR uses the OpenShift cluster&amp;#8217;s authentication server for user authentication.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Future plans for ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR is still a young project, and the worlds of containers and monitoring are always expanding, so there is a lot on our horizon. In the future, we hope to make the following changes and improvements to ContainerJFR:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Implement better and more flexible ways for ContainerJFR to identify, group, and label target applications. One example is the ability to examine OpenShift or Kubernetes labels and annotations.&lt;/li&gt; &lt;li&gt;Add support for batched operations, used to manage recordings across a group of targets with a single request.&lt;/li&gt; &lt;li&gt;Add a Trigger feature to allow recordings to be automatically started and stopped on a target or group of targets when a predefined event occurs. For example, when a new target appears, automatically start a recording with a predefined template.&lt;/li&gt; &lt;li&gt;Embed Grafana views and other visualizations directly into the ContainerJFR web client.&lt;/li&gt; &lt;li&gt;Provide integration or deep linking to the desktop JDK Mission Control application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;ContainerJFR repository&lt;/a&gt; for future updates.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#038;title=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/" data-a2a-title="Introduction to ContainerJFR: JDK Flight Recorder for containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;Introduction to ContainerJFR: JDK Flight Recorder for containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PPHmWvkzro8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;OpenJDK has long been a top pick for real-world applications and workloads, chosen for its blend of performance, compatibility, reliability, and observability. For many years, JDK Flight Recorder (JFR) and JDK Mission Control (JMC) have contributed to OpenJDK&amp;#8217;s success. Until recently, both were commercial features, however, available only for certain users and workloads. In 2018, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;Introduction to ContainerJFR: JDK Flight Recorder for containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">798277</post-id><dc:creator>Andrew Azores</dc:creator><dc:date>2021-01-25T08:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/</feedburner:origLink></entry><entry><title type="html">Developping on OpenShift with WildFly bootable jar</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/TUnRnG-StuA/" /><author><name>Emmanuel Hugonnet</name></author><id>https://wildfly.org//news/2021/01/24/odo-bootable-jar/</id><updated>2021-01-24T00:00:00Z</updated><content type="html">With the bootable jar feature of WildFly it is now easier to build applications for the cloud. You can trim the server to reduce its footprint which makes this a perfect candidate to build microservices on the cloud. Let’s discover how to combine this feature to build and deploy applications on OpenShift. USING ODO is a fast, iterative, and straightforward CLI tool for developers who write, build, and deploy applications on Kubernetes and OpenShift. odo abstracts away complex Kubernetes and OpenShift concepts for the developer. INSTALLING ODO Download the binary from according to your target environment and follow the instructions from . Please note that you need at least the version 2.0.3 to use the devfile we will be using in the rest of this article. PREPARING OUR CLOUD ENVIRONEMENT During this article we will use the 'free' OpenShift that you can have with your account on website. Once you have your cloud environment we need to connect to it from odo. odo login https://api.sandbox.x8i5.p1.openshiftapps.com:6443 --token=sha256~################################# Connecting to the OpenShift cluster Logged into "https://api.sandbox.x8i5.p1.openshiftapps.com:6443" as "ehugonne1" using the token provided. You have access to the following projects and can switch between them with 'odo project set &lt;project-name&gt;': * ehugonne1-code ehugonne1-dev ehugonne1-stage Using project "ehugonne1-code". CREATING THE NEW PROJECT First we need to create a namespace in OpenShift: odo project create microprofile-config Now we can create our project using the microprofile-config quickstart sample project. mkdir odo-demo cd odo-demo odo create java-wildfly-bootable-jar --starter=microprofile-config Validation ✓ Checking devfile existence [19047ns] ✓ Creating a devfile component from registry: DefaultDevfileRegistry [31878ns] ✓ Validating devfile component [153099ns] Starter Project ✓ Downloading starter project microprofile-config from https://github.com/wildfly/quickstart.git [1m] Please use `odo push` command to create the component with source deployed This will create the microprofile-config quickstart Apache Maven project with a devfile.yaml that describe how the project will be built and run on OpenShift. This devfile is the entry point of our whole project, you may think of it as the pom.xml for the cloud. They are fully described on . Let’s take a quick look at the devfile and their main entry points. I’ll pass the starterProjects which are the quickstarts you can select when creating your initial project. First we can see that it defines two components: * a jaeger component that will provide an OpenTracing compatible server so that Eclipse MicroProfile OpenTracing applications can send traces to. * a wildfly component which is a simple Java image with Apache Maven where the application will be built and run. It exposes only the 8080 port for HTTP. * a m2-repository component which is a persistent volume that we will be using to avoid losing all the downloaded artefacts between each restart of the wildfly container. Then we have the list of commands available to build, debug and run our application: * build: this will compile and build a bootable jar from the sources. * run: this will start and run the bootable jar. * debug: this will start and run the bootable jar in debug mode. * dev-build: this will compile and build a bootable jar from the sources so that it can be used in developper mode which means the server won’t get rebuilt nor restarted when the application is modified. * dev-run: this will start and run the bootable jar in developper mode which means the server won’t get rebuilt nor restarted when the application is modified. * dev-debug: this will start and run the bootable jar in debug developper mode which means the server won’t get rebuilt nor restarted when the application is modified. * watch-build: this will do nothing except print a nice message. * watch-run: this will start the bootable jar in watch mode. * watch-debug: this will start the bootable jar in watch mode with debug on. BUILDING AND RUNNING THE APPLICATION So let’s just build and start our application odo push Validation ✓ Validating the devfile [290197ns] Creating Kubernetes resources for component java-wildfly-bootable-jar ✓ Waiting for component to start [29s] Applying URL changes ✓ URL tracing-ui: http://tracing-ui-java-wildfly-bootable-jar-ehugonne1-code.apps.sandbox.x8i5.p1.openshiftapps.com/ created ✓ URL http: http://http-java-wildfly-bootable-jar-ehugonne1-code.apps.sandbox.x8i5.p1.openshiftapps.com/ created Syncing to component java-wildfly-bootable-jar ✓ Checking files for pushing [1ms] ✓ Syncing files to the component [4s] Executing devfile commands for component java-wildfly-bootable-jar ✓ Executing watch-build command "echo 'It's watcher mode Baby !!!''" [2s] ✓ Executing watch-run command "mvn ${MVN_ARGS_APPEND} -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" org.wildfly.plugins:wildfly-jar-maven-plugin:dev-watch -e -DskipTests", if not running [2s] Pushing devfile component java-wildfly-bootable-jar ✓ Changes successfully pushed to component You can get the url to access your application with oc get route java-wildfly-bootable-jar Now we can access the application on this URL. BUILDING AND DEBUGGING THE APPLICATION IN DEVELOPPER MODE To develop our application we provide a set of commands in to get feedbacks more quickly than with the default commands. Important The developper mode will only provision the server on the first build. That means that if you want to change the layers or the configuration of the server you will need to delete your application and push it again. So let’s start our server in developper mode with debug enabled. odo push --debug --build-command dev-build --debug-command dev-debug Validation ✓ Validating the devfile [165733ns] Creating Kubernetes resources for component java-jboss-eap-xp-bootable-jar ✓ Waiting for component to start [15s] Applying URL changes ✓ URL tracing-ui: http://tracing-ui-java-jboss-eap-xp-bootable-jar-microprofile-config.apps-crc.testing/ created ✓ URL http: http://http-java-jboss-eap-xp-bootable-jar-microprofile-config.apps-crc.testing/ created Syncing to component java-jboss-eap-xp-bootable-jar ✓ Checking files for pushing [2ms] ✓ Syncing files to the component [825ms] Executing devfile commands for component java-jboss-eap-xp-bootable-jar ✓ Executing dev-build command "mvn -Pbootable-jar -Dinsecure.repositories=WARN -Dmaven.repo.local=/home/jboss/.m2/repository -Dmaven.test.skip=true -Ddev package" [11m] ✓ Executing dev-debug command "mvn -Pbootable-jar -Dinsecure.repositories=WARN -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" -Dwildfly.bootable.jvmArguments=\"-agentlib:jdwp=transport=dt_socket,address=0.0.0.0:${DEBUG_PORT},server=y,suspend=n\" -Dmaven.repo.local=/home/jboss/.m2/repository wildfly-jar:dev", if not running [1s] Pushing devfile component java-jboss-eap-xp-bootable-jar ✓ Changes successfully pushed to component If we edit the source code and push our changes you can see that the deployment is quicker. Now let’s try to debug our application. First we need to create a tunnel to access the listening debug port on our application, so in a new terminal we need to execute: odo debug port-forward -l 8787 Started port forwarding at ports - 8787:5858 Now we can connect to debug our application on port 8787 with our IDE and debug as usual. Quite simple is’nt it ? USING THE WATCH MODE Now that we managed to build, run and debug our application on OpenShift we still need to execute commands to push our changes to the cloud. It would be nice to just have things updated automatically. odo provides a nice watch command that will push changes to OpenShift. But the bootable maven plugin offers also a watch mode that will have it recompile the application and redeploy it automatically when the code change. So let’s take advantage of those two modes. First we need to start our application in debug and watch mode: odo push --debug --build-command watch-build --debug-command watch-debug Validation ✓ Validating the devfile [34305ns] Creating Kubernetes resources for component java-wildfly-bootable-jar ✓ Waiting for component to start [21s] Applying URL changes ✓ URLs are synced with the cluster, no changes are required. Syncing to component java-wildfly-bootable-jar ✓ Checking file changes for pushing [1ms] ✓ Syncing files to the component [4s] Executing devfile commands for component java-wildfly-bootable-jar ✓ Executing watch-build command "echo 'It's watcher mode Baby !!!''" [812ms] ✓ Executing watch-debug command "mvn ${MVN_ARGS_APPEND} -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" -Dwildfly.bootable.jvmArguments=\"-agentlib:jdwp=transport=dt_socket,address=0.0.0.0:${DEBUG_PORT},server=y,suspend=n\" org.wildfly.plugins:wildfly-jar-maven-plugin:dev-watch -e", if not running [2s] Pushing devfile component java-wildfly-bootable-jar ✓ Changes successfully pushed to component Now we can set odo in watch mode too: odo watch Component is running in debug mode Please start port-forwarding in a different terminal Waiting for something to change in /home/ehsavoie/tmp/test When you edit a file like src/main/resources/META-INF/microprofile-config.properties, you can see the following on the console: File /home/ehsavoie/tmp/test/src/main/resources/META-INF/microprofile-config.properties changed Pushing files... Validation ✓ Validating the devfile [145787ns] Creating Kubernetes resources for component java-wildfly-bootable-jar ✓ Waiting for component to start [132ms] Applying URL changes ✓ URLs are synced with the cluster, no changes are required. Syncing to component java-wildfly-bootable-jar ✓ Checking file changes for pushing [1ms] ✓ Syncing files to the component [994ms] Executing devfile commands for component java-wildfly-bootable-jar ✓ Executing watch-build command "echo 'It's watcher mode Baby !!!''" [808ms] ✓ Executing watch-debug command "mvn ${MVN_ARGS_APPEND} -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" -Dwildfly.bootable.jvmArguments=\"-agentlib:jdwp=transport=dt_socket,address=0.0.0.0:${DEBUG_PORT},server=y,suspend=n\" org.wildfly.plugins:wildfly-jar-maven-plugin:dev-watch -e", if not running [851ms] Component is running in debug mode Please start port-forwarding in a different terminal Waiting for something to change in /home/ehsavoie/tmp/test And of course since we used a debug command, you can connect your IDE on port 8787 and debug as usual. So as we have seen, developping on OpenShift is now very easy and simple and almost as slick as local development. All the more so as you can add several containers on your pod. In the sample devfile that is provided you have a Jaeger Server that is running. Connecting to its web interface (exposed throught a route too), you can see the traces produced by our application.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/TUnRnG-StuA" height="1" width="1" alt=""/&gt;</content><dc:creator>Emmanuel Hugonnet</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/01/24/odo-bootable-jar/</feedburner:origLink></entry></feed>
